{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7f36385a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import all the necessary libraries/modules\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests   # Optional\n",
    "from bs4 import BeautifulSoup    # Optionalt\n",
    "from datetime import datetime\n",
    "import sqlite3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e2641441",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Function to log progress messages with timestamps\n",
    "def log_progress(message):\n",
    "    timestamp_format = \"%Y-%m-%d-%H:%M:%S\"    # Year-month-day-Hour:Minute:Second\n",
    "    now = datetime.now()\n",
    "    timestamp = now.strftime(timestamp_format)\n",
    "    \n",
    "    with open(\"code_log.txt\", \"a\") as f:      # Append mode to keep a continuous log\n",
    "        f.write(f\"{timestamp}: {message} \\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c5fec0c",
   "metadata": {},
   "source": [
    "## TASK 1 - EXTRACTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "519cd079",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract data from the URL\n",
    "def extract(url):\n",
    "    tables = pd.read_html(url)    # Read HTML tables into a list of DataFrames\n",
    "    df = tables[1]                # Select the second table (index 1)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0eaf857",
   "metadata": {},
   "source": [
    "**The extraction task is pretty small by the way...**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc67eabc",
   "metadata": {},
   "source": [
    "## TASK 2 - TRANSFORMATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e0283072",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Function to transform the extracted data\n",
    "def transform(df):\n",
    "\n",
    "    df = df.iloc[:, 1:]    # Keep only the necessary columns (excluding the first)\n",
    "    \n",
    "    # Rename columns for clarity\n",
    "    df.columns = [\"Name\", \"MC_USD_Billion\"]    # MC stands for Market Cap \n",
    "    \n",
    "    # Convert market cap to GBP, EUR, and INR\n",
    "    df[\"MC_GBP_Billion\"] = round(df[\"MC_USD_Billion\"] * 0.8, 2)\n",
    "    df[\"MC_EUR_Billion\"] = round(df[\"MC_USD_Billion\"] * 0.93, 2)\n",
    "    df[\"MC_INR_Billion\"] = round(df[\"MC_USD_Billion\"] * 82.95, 2)\n",
    "    \n",
    "    # Our final columns will look something like this - Name, MC_USD_Billion, MC_GBP_Billion, MC_EUR_Billion, MC_INR_Billion\\\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1060997",
   "metadata": {},
   "source": [
    "**Not that hard...**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2096295c",
   "metadata": {},
   "source": [
    "## TASK 3 - LOADING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6e50fc2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to load data into a CSV file\n",
    "def load_to_csv(df, csv_file_name):\n",
    "    df.to_csv(csv_file_name, index=False)    # Save DataFrame to CSV without row indices\n",
    "    \n",
    "# Function to load data into a database\n",
    "def load_to_db(df, db_name, tb_name):\n",
    "    conn = sqlite3.connect(db_name)          # Connect to the SQLite database\n",
    "    df.to_sql(tb_name, conn, if_exists=\"replace\", index=False)    # Replace table if it exists"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2268f1d",
   "metadata": {},
   "source": [
    "**Our ETL Job is actually finished, but we gotta make a function which will run some queries and can get some information out for us from the database**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7f4f65b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to run a query on the database and print the results\n",
    "def run_query(query_statement, db_name):\n",
    "    conn = sqlite3.connect(db_name)          # Connect to the SQLite database\n",
    "    query_output = pd.read_sql(query_statement, conn)    # Execute the query and read the results into a DataFrame\n",
    "    print(query_statement)\n",
    "    print(query_output)\n",
    "    conn.close()       # Close the database connection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "656c9385",
   "metadata": {},
   "source": [
    "**Let's call out all the functions and combine all of 'em with `log_progress()` in order to complete our ETL Job**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5855ff2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SELECT * FROM largest_banks\n",
      "                                      Name  MC_USD_Billion  MC_GBP_Billion  \\\n",
      "0                           JPMorgan Chase          432.92          346.34   \n",
      "1                          Bank of America          231.52          185.22   \n",
      "2  Industrial and Commercial Bank of China          194.56          155.65   \n",
      "3               Agricultural Bank of China          160.68          128.54   \n",
      "4                                HDFC Bank          157.91          126.33   \n",
      "5                              Wells Fargo          155.87          124.70   \n",
      "6                        HSBC Holdings PLC          148.90          119.12   \n",
      "7                           Morgan Stanley          140.83          112.66   \n",
      "8                  China Construction Bank          139.82          111.86   \n",
      "9                            Bank of China          136.81          109.45   \n",
      "\n",
      "   MC_EUR_Billion  MC_INR_Billion  \n",
      "0          402.62        35910.71  \n",
      "1          215.31        19204.58  \n",
      "2          180.94        16138.75  \n",
      "3          149.43        13328.41  \n",
      "4          146.86        13098.63  \n",
      "5          144.96        12929.42  \n",
      "6          138.48        12351.26  \n",
      "7          130.97        11681.85  \n",
      "8          130.03        11598.07  \n",
      "9          127.23        11348.39  \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "SELECT AVG(MC_GBP_Billion) FROM largest_banks\n",
      "   AVG(MC_GBP_Billion)\n",
      "0              151.987\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "SELECT Name from largest_banks LIMIT 5\n",
      "                                      Name\n",
      "0                           JPMorgan Chase\n",
      "1                          Bank of America\n",
      "2  Industrial and Commercial Bank of China\n",
      "3               Agricultural Bank of China\n",
      "4                                HDFC Bank\n"
     ]
    }
   ],
   "source": [
    "# Let's call out all the functions and combine all of them with log_progress() in order to complete our ETL Job\n",
    "# Start the ETL job\n",
    "log_progress(\"ETL Job has started\")\n",
    "\n",
    "# Extraction Phase\n",
    "log_progress(\"Phase 1 Extraction has started\")\n",
    "url = \"https://web.archive.org/web/20230908091635%20/https://en.wikipedia.org/wiki/List_of_largest_banks\"\n",
    "df = extract(url)\n",
    "log_progress(\"Phase 1 Extraction has ended\")\n",
    "\n",
    "# Transformation Phase\n",
    "log_progress(\"Phase 2 Transformation has started\")\n",
    "df = transform(df)\n",
    "log_progress(\"Phase 2 Transformation has ended\")\n",
    "\n",
    "# Loading Phase\n",
    "log_progress(\"Phase 3 Loading has started\")\n",
    "\n",
    "# Load data to csv\n",
    "csv_file_name = \"largest_banks_data.csv\"\n",
    "load_to_csv(df, csv_file_name)\n",
    "\n",
    "# Load data to database \n",
    "db_name = \"banks.db\"\n",
    "tb_name = \"largest_banks\"\n",
    "load_to_db(df, db_name, tb_name)\n",
    "\n",
    "log_progress(\"Phase 3 Loading has Ended\")\n",
    "\n",
    "log_progress(\"Starting the running query\")\n",
    "\n",
    "# Start Running queries\n",
    "db_name = \"banks.db\"\n",
    "tb_name = \"largest_banks\"\n",
    "\n",
    "# Run query to select all data\n",
    "query_statement = f\"SELECT * FROM {tb_name}\"\n",
    "run_query(query_statement, db_name)\n",
    "print(\"\\n\")\n",
    "print(\"\\n\")\n",
    "\n",
    "# Run query to get the average market cap in GBP\n",
    "query_statement = f\"SELECT AVG(MC_GBP_Billion) FROM {tb_name}\"\n",
    "run_query(query_statement, db_name)\n",
    "print(\"\\n\")\n",
    "print(\"\\n\")\n",
    "\n",
    "# Run query to get the names of the first 5 banks\n",
    "query_statement = f\"SELECT Name from {tb_name} LIMIT 5\"\n",
    "run_query(query_statement, db_name)\n",
    "\n",
    "log_progress(\"Ending the running query\")\n",
    "\n",
    "# End the ETL job\n",
    "log_progress(\"ETL Job has ended\")\n",
    "# -------------------------------------------------------\n",
    "# Our ETL Job is done above this line."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "337180af",
   "metadata": {},
   "source": [
    "### Note to Viewers\n",
    "\n",
    "Check out the `largest_banks_data.csv` and `banks.db` to see the output of our ETL Job. Here you'll find the top 10 banks with their market cap in various currencies like USD, GBP, EUR, and INR. Also, review the `code_log.txt` to see the timestamps for each phase of the ETL Job."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d575e5d",
   "metadata": {},
   "source": [
    "# THANK YOU :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c2a2086",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
